{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\win10\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarabic.araby as araby\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.isri import ISRIStemmer\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing Functions\n",
    "stopWords = stopwords.words('arabic')\n",
    "\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = araby.normalize_alef(text) # change إأآا to ا\n",
    "    text = araby.normalize_teh(text) # change ة to ه\n",
    "    text = araby.normalize_hamza(text) # change ئ أ ؤ to ء\n",
    "    text = text.replace(\"ى\", 'ي') # replace ى with ي  BTW the parameteres written in reverse \n",
    "    text = text = text.replace(\"گ\", \"ك\") # replace \"گ\" with ك parameteres written in reverse \n",
    "\n",
    "    return text\n",
    "\n",
    "special_char = [\"!\",'\"',\"#\",\"%\",\"&\",\"'\",\"(\",\")\",\n",
    "                \"+\",\",\",\"-\",\".\",\"/\",\":\",\"<\",\"[\",\n",
    "                \"\\\\\",\"]\",\"*\",\"{\",\"|\",\"}\",\"-\",\"_\",\"0\",\n",
    "                \"1\", '2','3','4','5','6','7','8','9']\n",
    "\n",
    "arabic_punctuations = '''`÷×؛<>_()*&^%][ـ،/:\"؟.,'{}~¦+|!”…“–ـ'''\n",
    "\n",
    "def clean_text(text):\n",
    "    \n",
    "    for char in special_char:\n",
    "        text = text.replace(char,' ') # Cleaning special Characters\n",
    "    \n",
    "    text = text.translate(str.maketrans('','', arabic_punctuations)) # remove punctuation\n",
    "    text = text.replace('\\n', '') # removes line breaks\n",
    "    text = re.sub(r\"^\\s+\", \"\", text) # tirms left space\n",
    "    text = re.sub(r\"\\s+$\", \"\", text) # trims right space\n",
    "    text = re.sub(' +', ' ',text) # tirms any space more than one\n",
    "    text = ' '.join([word for word in text.split() if word not in stopwords.words(\"arabic\")]) # remove stopwords \n",
    "    text = text.strip()\n",
    "    text = araby.strip_diacritics(text) # removing حركات\n",
    "    \n",
    "    return text\n",
    "\n",
    "def light_stem(text):\n",
    "    words = text.split()\n",
    "    result = list()\n",
    "    stemmer = ISRIStemmer()\n",
    "    for word in words:\n",
    "        word = stemmer.norm(word, num=1)      # remove diacritics which representing Arabic short vowels\n",
    "        if not word in stemmer.stop_words:    # exclude stop words from being processed\n",
    "            word = stemmer.pre32(word)        # remove length three and length two prefixes in this order\n",
    "            word = stemmer.suf32(word)        # remove length three and length two suffixes in this order\n",
    "            word = stemmer.waw(word)          # remove connective ‘و’ if it precedes a word beginning with ‘و’\n",
    "            word = stemmer.norm(word, num=2)  # normalize initial hamza to bare alif\n",
    "        result.append(word)\n",
    "    return ' '.join(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('new_poems_5top_v2.csv')  \n",
    "df['poem_text'] = df['poem_text'].apply(lambda x: clean_text(x)) # Cleaning poem text\n",
    "df['poem_text'] = df['poem_text'].apply(lambda x: light_stem(x)) # Normalizing poem text\n",
    "df['poem_text'] = df['poem_text'].apply(lambda x: normalize_text(x)) # Stemming poem text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('new_poems_5top_CNS2.csv', index = False) # Cleaned, Normalized and Stemmed poems.  2 number addressing version 2"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
